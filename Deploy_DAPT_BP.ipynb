{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a9042e4",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fdbbb9",
   "metadata": {},
   "source": [
    "This notebook walks you through the end-to-end workflow for domain-adaptive pretraining (DAPT) and supervised fine-tuning (SFT) of large language models. Using NVIDIA NeMo Curator for data curation and the NeMo Framework for training, you will curate domain-specific datasets, adapt a tokenizer, pretrain and fine-tune the model, evaluate performance, and deploy with NVIDIA NIM. The result is a complete, adaptable pipeline for building domain-specialized LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea282695",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "1. [Data Curation](#1-data-curation)  \n",
    "2. [Custom Tokenizer Training](#2-custom-tokenizer-training)  \n",
    "3. [Domain-Adaptive Pretraining](#3-domain-adaptive-pretraining)  \n",
    "4. [Supervised Fine-Tuning (SFT)](#4-supervised-fine-tuning-sft)  \n",
    "5. [Optimized Deployment](#5-optimized-deployment)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e331faf",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "#### 1. Data Curation  \n",
    "- **Efficient DAPT Data Curation** – Best practices for building high-quality domain corpora using open-source datasets.  \n",
    "- **Scalable Processing Pipeline** – Text extraction, filtering, deduplication, and data blending with NeMo Curator for large-scale datasets.  \n",
    "\n",
    "#### 2. Custom Tokenizer Training  \n",
    "- **Domain-Specific Tokenization** – Improve efficiency on specialized data.  \n",
    "- **Low-Overhead Adaptation** – Minimize retraining and fine-tuning effort.  \n",
    "- **Balanced Performance** – Optimize for domain data while preserving general-purpose capability.  \n",
    "\n",
    "#### 3. Domain-Adaptive Pretraining  \n",
    "- **Data Preprocessing** – Prepare curated text for pretraining.  \n",
    "- **Optimized Training** – Efficiently adapt LLMs to new domains.  \n",
    "- **Evaluation** – Compare baseline and domain-adapted models.  \n",
    "\n",
    "#### 4. Supervised Fine-Tuning (SFT)  \n",
    "- **Custom DataModules** – Build DataModule classes for SFT datasets.  \n",
    "- **Task Adaptation** – Fine-tune LLMs to improve task performance.  \n",
    "- **Inference** – Generate outputs with fine-tuned models.  \n",
    "- **Evaluation** – Assess model quality on curated benchmarks. \n",
    "\n",
    "#### 5. Reasoning [TO DO]\n",
    "\n",
    "\n",
    "#### 5. Optimized Deployment  \n",
    "- **Checkpoint Conversion** – Export to Hugging Face–compatible format.  \n",
    "- **NIM Deployment** – Build optimized inference engines and deploy with NVIDIA NIM.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69498b6a",
   "metadata": {},
   "source": [
    "# Getting Started\n",
    "1. [Prerequisites](#prerequisites)  \n",
    "2. [Launch Docker Container](#prerequisites)\n",
    "3. [Data Curation](#data-curation)\n",
    "4. [Custom Tokenizer Training](#custom-tokenizer-training)\n",
    "5. [Domain Adaptive Pretraining](#domain-adaptive-training)\n",
    "6. [Supervised Fine Tuning](#supervised-fine-tuning)\n",
    "7. [Deployment]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1f264d",
   "metadata": {},
   "source": [
    "### Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a1cae3",
   "metadata": {},
   "source": [
    "#### Hardware [TO DO]- GPU, CPU, system memory, disk space\n",
    "\n",
    "1. Launchable this version\n",
    "2. Make a README.md for the github\n",
    "3. Data Paths & Notebook Paths must be modified\n",
    "4. Reasoning Sections\n",
    "5. Add software components before the prerequisites\n",
    "6. NVAIE License- Swastika to check\n",
    "7. Add technical diagram- right below the introduction\n",
    "8. Remove evals folder (add to features coming soon section)\n",
    "9. [NVIDIA-AI-Blueprints/financial-fraud-detection](https://github.com/NVIDIA-AI-Blueprints/Financial-Fraud-Detection/)\n",
    "10. Use case description, modify table of contents, Target Audience\n",
    "11. Directory Structure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b4b5f6",
   "metadata": {},
   "source": [
    "#### Clone repository and install software"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4de8fd",
   "metadata": {},
   "source": [
    "1. **Clone** Git Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f58b04",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!git clone https://gitlab-master.nvidia.com/swastikad/dapt_bp_mirror.git"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cba490",
   "metadata": {},
   "source": [
    "2. **Install** [Docker](https://docs.docker.com/engine/install/ubuntu/)\n",
    "\n",
    "**Tip:** Ensure the Docker Compose plugin version is 2.29.1 or higher. Run docker compose version to confirm. Refer to Install the Compose plugin Docker documentation for more information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7038f7e9",
   "metadata": {},
   "source": [
    "3. **Install** [NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html#installing-the-nvidia-container-toolkit) to configure Docker for GPU-accelerated containers, for example NVIDIA NIM, NeMo Framework container etc. If you are using a system deployed with Brev you can skip this step since Brev systems come with NVIDIA Container Toolkit preinstalled.\n",
    "\n",
    "**Note:** After installing the toolkit, follow the instructions in the Configure Docker section in the NVIDIA Container Toolkit documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3f813b",
   "metadata": {},
   "source": [
    "#### Get API Keys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd739504",
   "metadata": {},
   "source": [
    "**Let's start by logging into the NVIDIA Container Registry.**\n",
    "\n",
    "The NVIDIA NGC API Key is a mandatory key that is required to use this blueprint. This is needed to log into the NVIDIA container registry, nvcr.io, and to pull secure container images used in this NVIDIA NIM Blueprint. Refer to [Generating NGC API Keys](https://docs.nvidia.com/ngc/gpu-cloud/ngc-user-guide/index.html#generating-api-key) in the NVIDIA NGC User Guide for more information.\n",
    "\n",
    "Authenticate with the NVIDIA Container Registry with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99375ba2",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "!docker login nvcr.io"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af89ad7a",
   "metadata": {},
   "source": [
    "**Note:** Use oauthtoken as the username and your API key as the password. The $oauthtoken username is a special name that indicates that you will authenticate with an API key and not a user name and password.After installing the toolkit, follow the instructions in the Configure Docker section in the NVIDIA Container Toolkit documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52b7be4",
   "metadata": {},
   "source": [
    "### Launch NeMo Framework Docker Container\n",
    "\n",
    "Run the following commands in your terminal to launch the NeMo Framework container.  \n",
    "All objectives from Sections **1–4** (Data Curation through Supervised Fine-Tuning) will be executed inside this container.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e4d7a0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "```\n",
    "docker pull nvcr.io/nvidia/nemo:25.04\n",
    "docker run -it --rm --gpus '\"device=0,1' --ipc=host --network host -v $(pwd):/workspace nvcr.io/nvidia/nemo:25.04\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e111c5",
   "metadata": {},
   "source": [
    "### Data Curation\n",
    "[TO DO]- Add a one liner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca31562",
   "metadata": {},
   "source": [
    "We will use the datasets in the `dapt-curation/code/data` folder to illustrate data curation with this pipeline. Sample data is collected from:  \n",
    "\n",
    "- **GitHub** – `/domain-specific-llms/data/dapt-sources/raw/github`  \n",
    "  (Clone repositories, extract text from source files, and convert to JSONL.)  \n",
    "- **ArXiv PDFs** – `/domain-specific-llms/data/dapt-sources/raw/arxiv_pdfs`  \n",
    "  (Extract text from PDFs, convert to TXT, and store as JSONL.)  \n",
    "- **Wikipedia** – `/domain-specific-llms/data/dapt-sources/raw/wikipedia`  \n",
    "  (Parse HTML pages, convert to TXT, and store as JSON.)  \n",
    "\n",
    "---\n",
    "\n",
    "#### Tutorial Steps  \n",
    "\n",
    "1. **Install requirements and import libraries**  \n",
    "2. **Download raw data** from GitHub repos, Wikipedia URLs, and ArXiv PDFs; extract metadata and convert to JSONL  \n",
    "3. **Load datasets** into the workspace  \n",
    "4. *(Optional)* **Inspect file types and sizes**  \n",
    "5. **Run the NeMo Curator pipeline:**  \n",
    "   - File type identification and separation  \n",
    "   - Document-level exact deduplication  \n",
    "   - Heuristic-based quality filtering (line count, word count, frequent N-grams, etc.)  \n",
    "   - Unicode error correction with *ftfy*  \n",
    "   - PII redaction  \n",
    "   - GPU-accelerated fuzzy and semantic deduplication  \n",
    "6. **Save filtered and curated data**  \n",
    "7. **Blend and shuffle datasets**  \n",
    "\n",
    "---\n",
    "\n",
    "#### Usage\n",
    "\n",
    "For custom installations inside container\n",
    "\n",
    "``` bash\n",
    "pip uninstall nemo-curator\n",
    "rm -r /opt/NeMo-Curator\n",
    "git clone --branch v0.9.0 https://github.com/NVIDIA/NeMo-Curator.git /opt/NeMo-Curator\n",
    "pip install --extra-index-url https://pypi.nvidia.com \"/opt/NeMo-Curator[all]\"\n",
    "```\n",
    "\n",
    "Then, install the following dependencies for running the DAPT tutorial:\n",
    "\n",
    "``` bash\n",
    "\n",
    "apt update\n",
    "apt-get install poppler-utils\n",
    "apt-get install tesseract-ocr\n",
    "apt install libtesseract-dev\n",
    "pip install -r /workspace/domain-specific-llms/src/dapt_curation/requirements.txt\n",
    "pip uninstall --yes $(pip list --format=freeze | grep opencv)\n",
    "rm -rf /usr/local/lib/python3.10/dist-packages/cv2/\n",
    "pip install \"opencv-python-headless<4.9.0\" # Since we want to use numpy<2\n",
    "python -c \"import nltk; nltk.download('punkt_tab')\"\n",
    "python -c \"import nltk; nltk.download('averaged_perceptron_tagger_eng')\"\n",
    "cd ./domain-specific-llms\n",
    "python ./deploy/01_data_curation/01_dapt_data_curation.py --device \"gpu\"\n",
    "\n",
    "```\n",
    "\n",
    "This will download chip-design related datasets and begin the data curation pipeline.\n",
    "\n",
    "Please use `--device \"gpu\"` to enable semantic and fuzzy deduplication, which require the GPU.\n",
    "\n",
    "---\n",
    "\n",
    "#### What Happens During Execution\n",
    "\n",
    "- Ingestion: Raw documents are loaded into a distributed Dask pipeline.\n",
    "- Normalization: Content is standardized (stripped boilerplate, converted to plain text).\n",
    "- Filtering: Each document is scored and selectively removed based on chosen filters.\n",
    "- Deduplication: Near-duplicate documents are detected and dropped to reduce redundancy.\n",
    "- Packaging: The curated dataset is written to disk in shard format for downstream use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73a5010",
   "metadata": {},
   "source": [
    "### Custom Tokenizer Training\n",
    "\n",
    "Custom tokenizers are trained or adapted to better capture domain-specific vocabulary, acronyms, and expressions. This preserves key terms as single tokens, reducing fragmentation and improving representational efficiency.  \n",
    "\n",
    "To get started, navigate to the tokenizer training directory:\n",
    "\n",
    "```bash\n",
    "cd dapt_bp_mirror/step2-custom-token-pretraining/02_custom_tokenizer_training\n",
    "```\n",
    "Then open and follow the notebook:\n",
    "\n",
    "`custom_tokenization_llama7b.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa13405b",
   "metadata": {},
   "source": [
    "### Domain Adaptive Continued Training\n",
    "\n",
    "**Domain-Adaptive Pretraining (DAPT)** specializes a general-purpose LLM (e.g., Llama-2-7B) on domain-specific text, improving accuracy and context-awareness for specialized tasks while retaining general language capabilities.  \n",
    "\n",
    "To get started, navigate to the DAPT training directory:\n",
    "\n",
    "```bash\n",
    "cd dapt_bp_mirror/step3-domain-adaptive-pretraining/03_domain_adaptive_pretraining\n",
    "```\n",
    "Then open and follow the notebook:\n",
    "\n",
    "`domain_adaptive_pretraining_nemo2.0.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c990c365",
   "metadata": {},
   "source": [
    "### Supervised Fine-Tuning (SFT)\n",
    "\n",
    "**Supervised Fine-Tuning (SFT)** further customizes a pretrained or domain-adapted model using curated, high-quality labeled data to align performance with specific tasks or human preferences.  \n",
    "\n",
    "\n",
    "To get started, navigate to the SFT training directory:\n",
    "\n",
    "```bash\n",
    "cd dapt_bp_mirror/step4-supervised-fine-tuning\n",
    "```\n",
    "\n",
    "Then open and follow the notebook:\n",
    "\n",
    "`supervised_fine_tuning.ipynb`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7598a3",
   "metadata": {},
   "source": [
    "### NIM Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ea76d5",
   "metadata": {},
   "source": [
    "### NIM Deployment"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
